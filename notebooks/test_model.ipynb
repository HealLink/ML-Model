{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 21:29:12.289509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732199352.339091   69846 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732199352.354445   69846 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-21 21:29:12.463921: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ryanfikri/anaconda3/envs/capstone-project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the subword tokenizer\n",
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary='./mental_vocab_subwords.txt'\n",
    ")\n",
    "\n",
    "# initialize model\n",
    "model = tf.keras.models.load_model('first_iteration.keras')\n",
    "\n",
    "# initialize label encoder\n",
    "# Load the vocabulary from a file\n",
    "with open(\"label_vocabulary.txt\", \"r\") as f:\n",
    "    vocab = [line.strip() for line in f]\n",
    "\n",
    "def padding_func(sequences):\n",
    "  '''Generates padded sequences from a tf.data.Dataset'''\n",
    "\n",
    "  # Put all elements in a single ragged batch\n",
    "  sequences = sequences.ragged_batch(batch_size=sequences.cardinality())\n",
    "\n",
    "  # Output a tensor from the single batch\n",
    "  sequences = sequences.get_single_element()\n",
    "\n",
    "  # Pad the sequences\n",
    "  padded_sequences = tf.keras.utils.pad_sequences(sequences.numpy(), \n",
    "                                                  maxlen=500, \n",
    "                                                  truncating='post', \n",
    "                                                  padding='post'\n",
    "                                                 )\n",
    "\n",
    "  # Convert back to a tf.data.Dataset\n",
    "  padded_sequences = tf.data.Dataset.from_tensor_slices(padded_sequences)\n",
    "\n",
    "  return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 10  83  21 488 238]\n",
      " [  0   0   0   0   0]\n",
      " [  0   0   0   0   0]\n",
      " ...\n",
      " [  0   0   0   0   0]\n",
      " [  0   0   0   0   0]\n",
      " [  0   0   0   0   0]], shape=(500, 5), dtype=int32)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "[[9.7543848e-01 3.3598391e-11 7.2672541e-05 ... 2.4488727e-02\n",
      "  8.1130267e-08 3.5747860e-10]\n",
      " [2.7726456e-08 4.6485100e-02 6.1314758e-02 ... 2.3749687e-12\n",
      "  3.1681042e-04 1.4108206e-04]\n",
      " [2.7726456e-08 4.6485100e-02 6.1314758e-02 ... 2.3749687e-12\n",
      "  3.1681042e-04 1.4108206e-04]\n",
      " ...\n",
      " [2.7726456e-08 4.6485100e-02 6.1314758e-02 ... 2.3749687e-12\n",
      "  3.1681042e-04 1.4108206e-04]\n",
      " [2.7726456e-08 4.6485100e-02 6.1314758e-02 ... 2.3749687e-12\n",
      "  3.1681042e-04 1.4108206e-04]\n",
      " [2.7726456e-08 4.6485100e-02 6.1314758e-02 ... 2.3749687e-12\n",
      "  3.1681042e-04 1.4108206e-04]]\n",
      "Predicted class: Suicidal\n"
     ]
    }
   ],
   "source": [
    "rawtext_test = [\"i want to die\"]\n",
    "sequence_test = padding_func(tf.data.Dataset.from_tensors(tokenizer.tokenize(rawtext_test)))\n",
    "for element in sequence_test:\n",
    "    print(element)\n",
    "predictions = model.predict(sequence_test)\n",
    "\n",
    "# predictions will be a numpy array of shape (1, num_classes) with probabilities for each class\n",
    "print(predictions)\n",
    "\n",
    "# To get the predicted class index\n",
    "predicted_class_index = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "print(f\"Predicted class: {vocab[predicted_class_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
