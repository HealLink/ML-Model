{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 13:18:22.384509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733465902.460226  166880 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733465902.481688  166880 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-06 13:18:22.652673: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import-import\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable('capstone')\n",
    "class MatthewsCorrelationCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, dtype=None, name=\"matthews_correlation_coefficient\"):\n",
    "        super(MatthewsCorrelationCoefficient, self).__init__(name=name)\n",
    "        self.num_classes = num_classes\n",
    "        self.c = self.add_weight(name=\"total_correct_predicted\", initializer=\"zeros\", dtype=tf.float32)\n",
    "        self.s = self.add_weight(name=\"total_samples\", initializer=\"zeros\", dtype=tf.float32)\n",
    "        self.t = self.add_weight(name=\"num_true\", shape=(num_classes,), initializer=\"zeros\", dtype=tf.float32)\n",
    "        self.p = self.add_weight(name=\"num_pred\", shape=(num_classes,), initializer=\"zeros\", dtype=tf.float32)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert one-hot labels to integer labels\n",
    "        if len(y_true.shape) > 1:\n",
    "            y_true = tf.argmax(y_true, axis=-1)\n",
    "        if len(y_pred.shape) > 1:\n",
    "            y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        # Total number of samples\n",
    "        new_s = tf.cast(tf.size(y_true), tf.float32)\n",
    "        # Total number of correctly predicted labels\n",
    "        new_c = tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n",
    "        \n",
    "        # Update state\n",
    "        self.s.assign(tf.add(self.s, new_s))\n",
    "        self.c.assign(tf.add(self.c, new_c))\n",
    "\n",
    "        for k in range(self.num_classes):\n",
    "            k = tf.cast(k, y_true.dtype)\n",
    "            tk = tf.reduce_sum(tf.cast(tf.equal(y_true, k), tf.float32))\n",
    "            pk = tf.reduce_sum(tf.cast(tf.equal(y_pred, k), tf.float32))\n",
    "            self.t[k].assign(tf.add(self.t[k], tk))\n",
    "            self.p[k].assign(tf.add(self.p[k], pk))\n",
    "    \n",
    "    def result(self):\n",
    "        num = self.c * self.s - tf.reduce_sum(self.t * self.p)\n",
    "        denom_t = tf.reduce_sum(self.t * self.t)\n",
    "        denom_p = tf.reduce_sum(self.p * self.p)\n",
    "        denom = tf.sqrt((self.s**2 - denom_t) * (self.s**2 - denom_p))\n",
    "        \n",
    "        mcc = tf.divide(num, denom + 1e-6)\n",
    "        return mcc\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.c.assign(0)\n",
    "        self.s.assign(0)\n",
    "        self.t.assign(tf.zeros_like(self.t))\n",
    "        self.p.assign(tf.zeros_like(self.p))\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(MatthewsCorrelationCoefficient, self).get_config()\n",
    "        config.update({\n",
    "            \"num_classes\": self.num_classes\n",
    "            })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable('capstone')\n",
    "class Classifier(tf.keras.Model):\n",
    "  def __init__(self, tfhub_handle_encoder, num_classes, dropout_rate, l2):\n",
    "    super(Classifier, self).__init__(name=\"prediction\")\n",
    "    self.num_classes = num_classes\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.l2 = l2\n",
    "    self.tfhub_handle_encoder = tfhub_handle_encoder\n",
    "    self.encoder = hub.KerasLayer(self.tfhub_handle_encoder, trainable=True)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dense = tf.keras.layers.Dense(num_classes, kernel_regularizer=tf.keras.regularizers.l2(l2))\n",
    "\n",
    "  def call(self, preprocessed_text):\n",
    "    encoder_outputs = self.encoder(preprocessed_text)\n",
    "    pooled_output = encoder_outputs[\"pooled_output\"]\n",
    "    x = self.dropout(pooled_output)\n",
    "    x = self.dense(x)\n",
    "    return x\n",
    "  \n",
    "  def get_config(self):\n",
    "    config = super(Classifier, self).get_config()\n",
    "    config.update({\n",
    "        \"num_classes\": self.num_classes,\n",
    "        \"dropout_rate\": self.dropout_rate,\n",
    "        \"l2\": self.l2,\n",
    "        \"tfhub_handle_encoder\": self.tfhub_handle_encoder\n",
    "    })\n",
    "    return config\n",
    "  \n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733455540.887803  134376 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1733455540.889378  134376 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = tf.keras.models.load_model('../my_models/checkpoint_03.tf', custom_objects={\"Classifier\": Classifier,\n",
    "                                                                                 \"MatthewsCorrelationCoefficient\": MatthewsCorrelationCoefficient,\n",
    "                                                                                 \"AdamWeightDecay\": optimization.AdamWeightDecay,\n",
    "                                                                                 \"WarmUp\": optimization.WarmUp\n",
    "                                                                                 })\n",
    "# model = tf.saved_model.load(\"my_models/model_bert_en_uncased_L-12_H-768_A-12\")\n",
    "classes = np.array(['Anxiety', 'Bipolar', 'Depression', 'Normal', 'Personality disorder', 'Stress', 'Suicidal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (1 total):\n    * <tf.Tensor 'preprocessed_text:0' shape=(1,) dtype=string>\n  Keyword arguments: {'training': False}\n\n Expected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (1 total):\n    * {'input_mask': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_mask'),\n 'input_type_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_type_ids'),\n 'input_word_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_word_ids')}\n  Keyword arguments: {'training': True}\n\nOption 2:\n  Positional arguments (1 total):\n    * {'input_mask': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_mask'),\n 'input_type_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_type_ids'),\n 'input_word_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_word_ids')}\n  Keyword arguments: {'training': False}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtomorrow danish will give some presentation, he feel so nervous, what if he gets diarrhea\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# predictions will be a numpy array of shape (1, num_classes) with probabilities for each class\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(classes)\n",
      "File \u001b[0;32m~/anaconda3/envs/capstone-bert/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/capstone-bert/lib/python3.11/site-packages/tensorflow/python/saved_model/function_deserialization.py:335\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    332\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    333\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    334\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 335\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (1 total):\n    * <tf.Tensor 'preprocessed_text:0' shape=(1,) dtype=string>\n  Keyword arguments: {'training': False}\n\n Expected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (1 total):\n    * {'input_mask': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_mask'),\n 'input_type_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_type_ids'),\n 'input_word_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_word_ids')}\n  Keyword arguments: {'training': True}\n\nOption 2:\n  Positional arguments (1 total):\n    * {'input_mask': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_mask'),\n 'input_type_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_type_ids'),\n 'input_word_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name='input_word_ids')}\n  Keyword arguments: {'training': False}"
     ]
    }
   ],
   "source": [
    "text = tf.constant([\"tomorrow danish will give some presentation, he feel so nervous, what if he gets diarrhea\"])\n",
    "predictions = model.predict(text)\n",
    "\n",
    "# predictions will be a numpy array of shape (1, num_classes) with probabilities for each class\n",
    "print(classes)\n",
    "print(tf.nn.softmax(predictions))\n",
    "\n",
    "# To get the predicted class index\n",
    "predicted_class_index = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "print(f\"Predicted class: {classes[predicted_class_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
